id: ab7a881d07
name: Judge v2
description: BARS style prompt.
constrained_output:
- '1'
- '2'
- '3'
- '4'
- '5'
tags:
- tokens_5
- QA_evaluation
- BARS
version: 1
template_chat:
  system: "You will be given a user_question and system_answer couple.\nYour task\
    \ is to provide a 'total rating' scoring how well the system_answer answers the\
    \ user concerns expressed in the user_question.\nGive your answer as an integer\
    \ on a scale of 1 to 5, where 1 means that the system_answer is not helpful at\
    \ all, and 5 means that the answer completely and helpfully addresses the question.\n\
    \nHere is the scale you should use to build your answer:\n1: The system_answer\
    \ is terrible: completely irrelevant to the question asked, or very partial.\n\
    2: The system_answer is mostly not helpful: misses key aspects of the question\
    \ or misunderstands the user\u2019s intent.\n3: The system_answer is mostly helpful:\
    \ provides useful information but lacks depth, precision, or structure.\n4: The\
    \ system_answer is excellent: relevant, direct, detailed, and addresses all the\
    \ concerns raised in the question.\n5: The system_answer is outstanding: not only\
    \ complete and precise, but also insightful, well-structured, and engaging \u2014\
    \ it exceeds expectations by adding clarity, nuance, or empathy."
  user: 'Question:

    "{question}"


    Answer:

    "{answer}"'
